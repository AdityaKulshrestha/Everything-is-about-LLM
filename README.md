# Everything-is-about-LLM
A curated lists of blogs, papers, github repositories and colab notebooks covering everything about LLM from fine tuning to production.

# Top authors
- [Eugene Yan](https://eugeneyan.com/)
- [Lilian Weng](https://lilianweng.github.io/)
- [Sayak Paul's Roadmap](https://docs.google.com/document/u/0/d/1iQlsGOZX0UA3U58gEtwV5-9moolOvZ5HosjDee6jVck/mobilebasic)
- [Harsh Singhal's Ideas based on LLM](https://docs.google.com/document/u/0/d/1uFwAt2yxoJWX80gjoTNVPNaduUp-OvJQ_DxJUjKZzyc/mobilebasic)
- [Sebastian Raschka](https://substack.com/@rasbt)
- [Cameron Wolfe](https://cameronrwolfe.me/)

# Understanding Transformers 
- Blogs
  - [Visual Transformer](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
  - [Generative AI exists because of the transformer - Easy Scrollable Guide](https://ig.ft.com/generative-ai/)
- Youtube
  - [Serrano Academy - Large Language Models](https://www.youtube.com/watch?v=OxCpWwDCDFQ&list=PLs8w1Cdi-zva4fwKkl9EK13siFvL9Wewf)

# Fine Tuning 
- Libraries
  - HuggingFace
  - Replicate
- Papers
  - [QLora](https://arxiv.org/abs/2305.14314)
- Blogs
  - [Fine Tuning Embeddings for RAG based custom dataset](https://blog.llamaindex.ai/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971)
  - [Fine tuning a T5 transformers for any summarization task](https://towardsdatascience.com/fine-tuning-a-t5-transformer-for-any-summarization-task-82334c64c81)
  - [Fine tuning LLMs using PEFT Techniques](https://abvijaykumar.medium.com/fine-tuning-llm-parameter-efficient-fine-tuning-peft-lora-qlora-part-1-571a472612c4)
  - [Fine tuning LLama-2 by AnyScale](https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications)
 - Youtube
  - [RAG Implementation of medical Chatbot using Mitral 7B](https://www.youtube.com/watch?v=1mH1BvBJCl0)

# LLMs 
- FinGPT[Paper](https://arxiv.org/abs/2306.06031)
- Best Comprehensive Paper on LLMs (everything inclusive) [Paper](https://arxiv.org/html/2401.02038v2)
- [Working with LLMs: How to handle LLMs (Good Guide)](https://applied-llms.org/)

# Inference 
- [Mathematics on Inference](https://kipp.ly/transformer-inference-arithmetic/#latency-calculations)
- [Best Slides on Inference and issues around it](https://linden-li.github.io/posts/inference-slides?ref=jinghong-chen.net)
- [Optimized toolkit to deploy LLM - Sgrank](https://github.com/sgl-project/sglang)

# Embeddings 
- Use Cases
  - [Spam Classification using Embeddings](https://ahujaniharika95.medium.com/spam-classification-using-word2vec-embeddings-70c4ffa56b40)
- Blogs
  - [Embeddings: What are they?](https://simonwillison.net/2023/Oct/23/embeddings/)

# Quantization 
- Blogs
  - [Huggingface's intro to quantization](https://huggingface.co/blog/merve/quantization)
  - [Maarten Grootendorst: A visual guide to quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization

# Cost 
- [LLM cost estimation from fine tuning to inference](https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Resources)

# Production 
- Blogs
  - [How ByteDance Scales Offline Inference with multi-modal LLMs to 200 TB Data](https://www.anyscale.com/blog/how-bytedance-scales-offline-inference-with-multi-modal-llms-to-200TB-data)
  - [Building a RAG based production application - Anyscale](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)
  - [Recipe @ Zomato](https://blinkit.com/blog/recipe-rover)
  - [Zomato AI](https://blog.zomato.com/introducing-zomato-ai-your-foodie-buddy)
- Videos
  - [Zia @ Zomato Chatbot (Really good)](https://www.youtube.com/watch?v=4vTWd3QOlpg&t=1608s)
  - [Flipkart Enhances AI Safety in E-Commerce](https://blog.flipkart.tech/flipkart-enhances-ai-safety-in-e-commerce-implementing-nvidia-nemo-guardrails-cb2f293b29c0)
 
# LLM Tools 
- Nemo GuardRails
  - [The missing manual](https://www.pinecone.io/learn/nemo-guardrails-intro/)
- [LitGPT - Official starter kit for the NeurIPS 2023 LLM Efficiency Challenge](https://github.com/Lightning-AI/lit-gpt/tree/main)
- [Steaming LLM](https://github.com/mit-han-lab/streaming-llm)


# Optimization
- [Optimization LLMs from a dataset perspective](https://lightning.ai/pages/community/tutorial/optimizing-llms-from-a-dataset-perspective/)
- [Bringing the best of GPU](https://horace.io/brrr_intro.html)

# Evaluation of LLM 
- [Evaluating LLMs is a minefield - Princeton University](https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/)
- [Compiled Resources for LLM Evaluation](https://docs.google.com/document/u/0/d/1ndYxbN9O7dGKeVXR53B3xHFszniSyho6KLaq-aniDRo/mobilebasic)

# Tools
- [Ragas](https://github.com/explodinggradients/ragas)
- [Giskard](https://github.com/Giskard-AI/giskard)
 
# Hosting 
- Blogs
  - [Hosting a LLama Model on Colab](https://medium.com/@yuhongsun96/host-a-llama-2-api-on-gpu-for-free-a5311463c183)
  - 

# Tokenizers 
- Youtube
  - [What makes LLM tokenizers different from each other?](https://www.youtube.com/watch?v=rT6wVLEDC_w)

# Prompt Engineering
- [Try Prompt Hacking to know the passcode](https://gandalf.lakera.ai/)


# Agents 
- [Survey on Rise and Potential of LLM based Agents](https://github.com/WooooDyy/LLM-Agent-Paper-List)
- [Surver on LLM based AutoAgents](https://github.com/Paitesanshi/LLM-Agent-Survey#-more-comprehensive-summarization)
- [Working with Agents Lilian Blog](https://lilianweng.github.io/posts/2023-06-23-agent/)


# Tutorials 
- Youtube
  - [Neural Hacks with Vasanth](https://www.youtube.com/@NeuralHackswithVasanth/videos)

# Multimodal LLMs
- Papers
  - [Multimodal Foundation Models](https://arxiv.org/abs/2309.10020)
- Blogs
  - [Introduction to MultiModal LLM - Comet](https://www.comet.com/site/blog/an-introduction-to-multimodal-models/)


# Notebooks 
- [Graph RAG using Llama-index](https://colab.research.google.com/drive/1tLjOg2ZQuIClfuWrAC2LdiZHCov8oUbs?usp=sharing)
- OpenAI Cookbook [blog](https://cookbook.openai.com/) [github](https://github.com/openai/openai-cookbook/tree/main/examples)
- 
